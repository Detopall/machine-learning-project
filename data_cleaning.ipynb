{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project supervised learning - Drunk smurfs\n",
    "\n",
    "Jean-Baptiste Maene - Denis Topallaj - Lander Pauwels Malengier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_7852\\816365406.py:9: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "\n",
    "df = pd.read_csv('train_V2.csv')\n",
    "df_test = pd.read_csv('score.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Drop inconsistent or empty data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.1 Dropping reoccurring empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4947, 53)\n",
      "test (496, 50)\n"
     ]
    }
   ],
   "source": [
    "# when these three columns are not filled, the rest of the data is not filled.\n",
    "# the rows without data are dropped.\n",
    "\n",
    "indexes = df[(df['income_am'].isnull()) & (df['profit_last_am'].isnull()) & (df['profit_am'].isnull())].index\n",
    "\n",
    "df = df.drop(index=indexes.array)\n",
    "\n",
    "print('train', df.shape)\n",
    "\n",
    "# same with the test file\n",
    "\n",
    "indexes = df_test[(df_test['income_am'].isnull()) & (df_test['profit_last_am'].isnull()) & (df_test['profit_am'].isnull())].index\n",
    "\n",
    "df_test = df_test.drop(index=indexes.array)\n",
    "\n",
    "print('test', df_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.2 Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_am</th>\n",
       "      <th>profit_last_am</th>\n",
       "      <th>profit_am</th>\n",
       "      <th>damage_am</th>\n",
       "      <th>damage_inc</th>\n",
       "      <th>crd_lim_rec</th>\n",
       "      <th>credit_use_ic</th>\n",
       "      <th>gluten_ic</th>\n",
       "      <th>lactose_ic</th>\n",
       "      <th>insurance_ic</th>\n",
       "      <th>...</th>\n",
       "      <th>score1_pos</th>\n",
       "      <th>score1_neg</th>\n",
       "      <th>score2_pos</th>\n",
       "      <th>score2_neg</th>\n",
       "      <th>score3_pos</th>\n",
       "      <th>score3_neg</th>\n",
       "      <th>score4_pos</th>\n",
       "      <th>score4_neg</th>\n",
       "      <th>score5_pos</th>\n",
       "      <th>score5_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5660.0</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>8640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.396819</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>0.763608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3990.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1158.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4194.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009811</td>\n",
       "      <td>0.592842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252444</td>\n",
       "      <td>0.724693</td>\n",
       "      <td>0.818064</td>\n",
       "      <td>0.387361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2451.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>2119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>946.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>820.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>7794.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307239</td>\n",
       "      <td>0.660891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.914151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262224</td>\n",
       "      <td>8.060677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>6092.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419981</td>\n",
       "      <td>0.668320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2301.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837325</td>\n",
       "      <td>0.663044</td>\n",
       "      <td>0.697171</td>\n",
       "      <td>0.353229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>492.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3716.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461598</td>\n",
       "      <td>4.757132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>266.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643780</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     income_am  profit_last_am  profit_am  damage_am  damage_inc  crd_lim_rec  \\\n",
       "0       5660.0          4320.0     8640.0        0.0         0.0       8000.0   \n",
       "1       3990.0             9.0     3450.0        0.0         0.0      12500.0   \n",
       "2       1158.0            82.0     4194.0      408.0         4.0      12000.0   \n",
       "3       2451.0           791.0     2119.0        0.0         0.0          0.0   \n",
       "4        946.0           222.0     2036.0        0.0         0.0          0.0   \n",
       "..         ...             ...        ...        ...         ...          ...   \n",
       "495      820.0           216.0     7794.0     1103.0         3.0       9000.0   \n",
       "496     6092.0          2100.0     3137.0        0.0         0.0          0.0   \n",
       "497     2301.0           214.0     2516.0        0.0         0.0      11000.0   \n",
       "498      492.0             0.0     3716.0      713.0         2.0       5000.0   \n",
       "499      266.0            14.0     1769.0        0.0         0.0      11000.0   \n",
       "\n",
       "     credit_use_ic  gluten_ic  lactose_ic  insurance_ic  ...  score1_pos  \\\n",
       "0              0.0        0.0         1.0           0.0  ...    0.538419   \n",
       "1              0.0        0.0         0.0           1.0  ...         NaN   \n",
       "2              0.0        0.0         0.0           1.0  ...    0.009811   \n",
       "3              0.0        0.0         0.0           1.0  ...         NaN   \n",
       "4              0.0        0.0         1.0           0.0  ...         NaN   \n",
       "..             ...        ...         ...           ...  ...         ...   \n",
       "495            0.0        0.0         0.0           1.0  ...    0.307239   \n",
       "496            0.0        0.0         0.0           0.0  ...         NaN   \n",
       "497            0.0        0.0         0.0           0.0  ...    0.837325   \n",
       "498            0.0        0.0         0.0           1.0  ...         NaN   \n",
       "499            0.0        0.0         0.0           1.0  ...         NaN   \n",
       "\n",
       "     score1_neg  score2_pos  score2_neg  score3_pos  score3_neg  score4_pos  \\\n",
       "0      0.396819    0.423742    0.763608         NaN         NaN         NaN   \n",
       "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2      0.592842         NaN         NaN    0.252444    0.724693    0.818064   \n",
       "3           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "495    0.660891         NaN         NaN    0.738333    0.914151         NaN   \n",
       "496         NaN    0.419981    0.668320         NaN         NaN         NaN   \n",
       "497    0.663044    0.697171    0.353229         NaN         NaN         NaN   \n",
       "498         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "499         NaN         NaN         NaN    0.643780    0.447084         NaN   \n",
       "\n",
       "     score4_neg  score5_pos  score5_neg  \n",
       "0           NaN         NaN         NaN  \n",
       "1           NaN         NaN         NaN  \n",
       "2      0.387361         NaN         NaN  \n",
       "3           NaN         NaN         NaN  \n",
       "4           NaN         NaN         NaN  \n",
       "..          ...         ...         ...  \n",
       "495         NaN    0.262224    8.060677  \n",
       "496         NaN         NaN         NaN  \n",
       "497         NaN         NaN         NaN  \n",
       "498         NaN    0.461598    4.757132  \n",
       "499         NaN         NaN         NaN  \n",
       "\n",
       "[496 rows x 50 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()\n",
    "\n",
    "df_test.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.3 Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4947, 51)\n",
      "test (496, 48)\n"
     ]
    }
   ],
   "source": [
    "# score5_neg has scores ranging from 7995 trillion to -472 trillion and everything in between. score5_neg and score5_pos will be dropped.\n",
    "\n",
    "# looking at the score of the other four scoring systems we can confidently say that score5_neg can be dropped (score5_pos also has to be dropped, because they both make a pair)\n",
    "\n",
    "# quantile score can only range 0 < q < 1\n",
    "\n",
    "columns = [\"score5_neg\", \"score5_pos\"]\n",
    "\n",
    "for col in columns:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# dropping the score5 for the test data set\n",
    "\n",
    "for col in columns:\n",
    "    if col in df_test.columns:\n",
    "        df_test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print(\"train\", df.shape)\n",
    "print(\"test\", df_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.4 Dropping unethical/'useless' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4947, 48)\n",
      "test (496, 45)\n"
     ]
    }
   ],
   "source": [
    "# Having gender, place or origin, race ... as a factor to disallow smurfs from entering a hotel is unethical.\n",
    "\n",
    "if \"urban_ic\" in df.columns and \"neighbor_income\" in df.columns and \"gender\" in df.columns:\n",
    "\tdf = df.drop('urban_ic', axis=1)\n",
    "\tdf = df.drop('neighbor_income', axis=1)\n",
    "\tdf = df.drop('gender', axis=1)\n",
    " \n",
    "if \"urban_ic\" in df_test.columns and \"neighbor_income\" in df_test.columns and \"gender\" in df_test.columns:\n",
    "\tdf_test = df_test.drop('urban_ic', axis=1)\n",
    "\tdf_test = df_test.drop('neighbor_income', axis=1)\n",
    "\tdf_test = df_test.drop('gender', axis=1)\n",
    "\n",
    "print(\"train\", df.shape)\n",
    "print(\"test\", df_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      " cab_requests      35\n",
      "dining_ic         35\n",
      "presidential      35\n",
      "tenure_mts       339\n",
      "tenure_yrs       339\n",
      "shop_use          35\n",
      "score1_pos      3722\n",
      "score1_neg      3633\n",
      "score2_pos      3738\n",
      "score2_neg      3643\n",
      "score3_pos      3686\n",
      "score3_neg      3580\n",
      "score4_pos      3724\n",
      "score4_neg      3623\n",
      "dtype: int64\n",
      "\n",
      "test\n",
      " cab_requests      1\n",
      "dining_ic         1\n",
      "presidential      1\n",
      "tenure_mts       35\n",
      "tenure_yrs       35\n",
      "shop_use          1\n",
      "score1_pos      374\n",
      "score1_neg      362\n",
      "score2_pos      385\n",
      "score2_neg      372\n",
      "score3_pos      360\n",
      "score3_neg      351\n",
      "score4_pos      377\n",
      "score4_neg      370\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# These are the columns with missing data\n",
    "\n",
    "print(\"train\\n\", df.isnull().sum()[df.isnull().sum() != 0])\n",
    "\n",
    "print(\"\\ntest\\n\", df_test.isnull().sum()[df_test.isnull().sum() != 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.1 Using mean for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      " tenure_mts     339\n",
      "tenure_yrs     339\n",
      "score1_pos    3722\n",
      "score1_neg    3633\n",
      "score2_pos    3738\n",
      "score2_neg    3643\n",
      "score3_pos    3686\n",
      "score3_neg    3580\n",
      "score4_pos    3724\n",
      "score4_neg    3623\n",
      "dtype: int64\n",
      "\n",
      "test\n",
      " tenure_mts     35\n",
      "tenure_yrs     35\n",
      "score1_pos    374\n",
      "score1_neg    362\n",
      "score2_pos    385\n",
      "score2_neg    372\n",
      "score3_pos    360\n",
      "score3_neg    351\n",
      "score4_pos    377\n",
      "score4_neg    370\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df_mean_imputed = df.copy()\n",
    "\n",
    "# mean worthy columns\n",
    "columns = [\"cab_requests\", \"dining_ic\", \"presidential\", \"shop_use\"]\n",
    "\n",
    "for col in columns:\n",
    "\tmean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "\tmean_imputer = mean_imputer.fit(np.array(df[col]).reshape(-1, 1))\n",
    " \n",
    "\tdf_mean_imputed[col] = mean_imputer.transform(np.array(df[col]).reshape(-1, 1))\n",
    "\n",
    "print(\"train\\n\", df_mean_imputed.isnull().sum()[df_mean_imputed.isnull().sum() != 0])\n",
    "\n",
    "\n",
    "# using mean_imputer for the test data\n",
    "df_mean_imputed_test = df_test.copy()\n",
    "\n",
    "# mean worthy columns\n",
    "columns = [\"cab_requests\", \"dining_ic\", \"presidential\", \"shop_use\"]\n",
    "\n",
    "for col in columns:\n",
    "\tmean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "\tmean_imputer = mean_imputer.fit(np.array(df_test[col]).reshape(-1, 1))\n",
    " \n",
    "\tdf_mean_imputed_test[col] = mean_imputer.transform(np.array(df_test[col]).reshape(-1, 1))\n",
    "\n",
    "print(\"\\ntest\\n\", df_mean_imputed_test.isnull().sum()[df_mean_imputed_test.isnull().sum() != 0])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.2 Using KNN for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      " score1_pos    3722\n",
      "score1_neg    3633\n",
      "score2_pos    3738\n",
      "score2_neg    3643\n",
      "score3_pos    3686\n",
      "score3_neg    3580\n",
      "score4_pos    3724\n",
      "score4_neg    3623\n",
      "dtype: int64\n",
      "\n",
      "test\n",
      " score1_pos    374\n",
      "score1_neg    362\n",
      "score2_pos    385\n",
      "score2_neg    372\n",
      "score3_pos    360\n",
      "score3_neg    351\n",
      "score4_pos    377\n",
      "score4_neg    370\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN) Imputation will be used for \"tenure_mts\" and \"tenure_yrs\" because it is a good option when the missingness is random, and there is no clear pattern to the missing data.\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df_knn_imputed = df_mean_imputed.copy()\n",
    "\n",
    "columns = [\"tenure_mts\", \"tenure_yrs\"]\n",
    "\n",
    "for col in columns:\n",
    "\tknn_imputer = KNNImputer(n_neighbors=5)\n",
    "\timputed_col = knn_imputer.fit_transform(df_knn_imputed[[col]])\n",
    "\tdf_knn_imputed[col] = imputed_col\n",
    "\n",
    "print(\"train\\n\", df_knn_imputed.isnull().sum()[df_knn_imputed.isnull().sum() != 0])\n",
    "\n",
    "\n",
    "# using the KNNImputer for the test data set\n",
    "\n",
    "df_knn_imputed_test = df_mean_imputed_test.copy()\n",
    "\n",
    "columns = [\"tenure_mts\", \"tenure_yrs\"]\n",
    "\n",
    "for col in columns:\n",
    "\tknn_imputer = KNNImputer(n_neighbors=5)\n",
    "\timputed_col = knn_imputer.fit_transform(df_knn_imputed_test[[col]])\n",
    "\tdf_knn_imputed_test[col] = imputed_col\n",
    "\n",
    "print(\"\\ntest\\n\", df_knn_imputed_test.isnull().sum()[df_knn_imputed_test.isnull().sum() != 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.3 Handle missing data for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be looping over each row and averaging the scores inside the pos and neg column.\n",
    "\n",
    "# When there is no scores given by the staff, the score will default to 0.\n",
    "\n",
    "# In the end the columns will be dropped and replaced by two new columns: \"score_pos\" and \"score_neg\".\n",
    "\n",
    "# There are also checks added for when columns that need to be removed are already removed.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_scores(df, columns):\n",
    "\tfor i, row in df.iterrows():\n",
    "\t\tpos_sum = 0\n",
    "\t\tpos_count = 0\n",
    "\t\tneg_sum = 0\n",
    "\t\tneg_count = 0\n",
    "\t\tfor col in columns:\n",
    "\t\t\tif \"pos\" in col:\n",
    "\t\t\t\tif not np.isnan(row[col]):\n",
    "\t\t\t\t\tpos_sum += row[col]\n",
    "\t\t\t\t\tpos_count += 1\n",
    "\t\t\telif \"neg\" in col:\n",
    "\t\t\t\tif not np.isnan(row[col]):\n",
    "\t\t\t\t\tneg_sum += row[col]\n",
    "\t\t\t\t\tneg_count += 1\n",
    "\t\tif pos_count > 0:\n",
    "\t\t\tdf.at[i, 'score_pos'] = pos_sum / pos_count\n",
    "\t\tif neg_count > 0:\n",
    "\t\t\tdf.at[i, 'score_neg'] = neg_sum / neg_count\n",
    "\n",
    "\tdf['score_pos'].fillna(0, inplace=True)\n",
    "\tdf['score_neg'].fillna(0, inplace=True)\n",
    " \n",
    "\tdf.drop(columns=columns, inplace=True)\n",
    "\treturn df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'score1_neg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'score1_neg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# executing the function using the most recent dataFrame and the columns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mscore1_neg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore1_pos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore2_pos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore2_neg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore3_pos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore3_neg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore4_pos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore4_neg\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m df_knn_imputed \u001b[39m=\u001b[39m calculate_scores(df_knn_imputed, columns\u001b[39m=\u001b[39;49mcolumns)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mtrain\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, df_knn_imputed\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()[df_knn_imputed\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[113], line 23\u001b[0m, in \u001b[0;36mcalculate_scores\u001b[1;34m(df, columns)\u001b[0m\n\u001b[0;32m     21\u001b[0m \t\tpos_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m col:\n\u001b[1;32m---> 23\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misnan(row[col]):\n\u001b[0;32m     24\u001b[0m \t\tneg_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m row[col]\n\u001b[0;32m     25\u001b[0m \t\tneg_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'score1_neg'"
     ]
    }
   ],
   "source": [
    "# executing the function using the most recent dataFrame and the columns\n",
    "\n",
    "columns=[\"score1_neg\", \"score1_pos\", \"score2_pos\", \"score2_neg\", \"score3_pos\", \"score3_neg\", \"score4_pos\", \"score4_neg\"]\n",
    "\n",
    "df_knn_imputed = calculate_scores(df_knn_imputed, columns=columns)\n",
    "\n",
    "\n",
    "print(\"\\ntrain\\n\", df_knn_imputed.isnull().sum()[df_knn_imputed.isnull().sum() != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\ntrain\\n\", df_knn_imputed.isnull().sum()[df_knn_imputed.isnull().sum() != 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Changing data types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3.1 changing floats to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[0;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m df_knn_imputed[col]\u001b[39m.\u001b[39mempty:\n\u001b[1;32m---> 10\u001b[0m         df_knn_imputed[col] \u001b[39m=\u001b[39m df_knn_imputed[col]\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49muint8)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, df_knn_imputed\u001b[39m.\u001b[39minfo())\n\u001b[0;32m     14\u001b[0m \u001b[39m# change type to uint8 for the test data set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:140\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot astype a timedelta from [\u001b[39m\u001b[39m{\u001b[39;00marr\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m] to [\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m is_integer_dtype(dtype):\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[0;32m    142\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m     \u001b[39m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[39m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[1;32mc:\\Users\\denis\\.virtualenvs\\project-KreOZjcw\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(values)\u001b[39m.\u001b[39mall():\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m    183\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m     \u001b[39m# GH#45151\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (values \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall():\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "# These columns are not meant to be floats.\n",
    "# ex.: You cannot have 0.214 of a child.\n",
    "# The few that are floats are price or time related.\n",
    "\n",
    "columns = [\"damage_inc\", \"credit_use_ic\", \"gluten_ic\", \"lactose_ic\", \"insurance_ic\", \"spa_ic\", \"empl_ic\", \"cab_requests\", \"bar_no\", \"sport_ic\", \"age\", \"marketing_permit\", \"dining_ic\", \"presidential\", \"client_segment\", \"sect_empl\", \"prev_stay\", \"prev_all_in_stay\", \"divorce\", \"fam_adult_size\", \"children_no\", \"tenure_mts\", \"tenure_yrs\", \"company_ic\", \"claims_no\", \"nights_booked\", \"shop_use\", \"retired\", \"gold_status\"]\n",
    "\n",
    "\n",
    "for col in columns:\n",
    "    if not df_knn_imputed[col].empty:\n",
    "        df_knn_imputed[col] = df_knn_imputed[col].astype(np.uint8)\n",
    "        \n",
    "print(\"train\\n\", df_knn_imputed.info())\n",
    "\n",
    "# change type to uint8 for the test data set\n",
    "\n",
    "for col in columns:\n",
    "    if not df_knn_imputed_test[col].empty:\n",
    "        df_knn_imputed_test[col] = df_knn_imputed_test[col].astype(np.uint8)\n",
    "\n",
    "print(\"\\ntest\\n\", df_knn_imputed_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting True to 1 and False to 0\n",
    "\n",
    "def replace_true_false(dataframe, column_name):\n",
    "    dataframe[column_name] = dataframe[column_name].replace({True: 1, False: 0})\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the function and replacing the new dataFrame\n",
    "\n",
    "df_knn_imputed = replace_true_false(df_knn_imputed, 'married_cd')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Storing cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cleaned csv will now be in the file train_V2_cleaned and will be used for the rest of the calculations\n",
    "\n",
    "df_knn_imputed.to_csv('train_V2_cleaned.csv', index=False)\n",
    "df_knn_imputed.to_csv('score_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-KreOZjcw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d6a6c385d3b1ee503ef124f4469fd6e96237536029e6cbf9e56f9fb8117ec4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
